{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee759a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\ana\\envs\\idls24\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, json, random\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1b4ec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_json(path: Path, obj):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def tokenize_dataset(ds, tok, max_len):\n",
    "    ds = ds.filter(lambda ex: ex.get(\"text\", None) and len(ex[\"text\"].strip()) > 0)\n",
    "\n",
    "    def _map(ex):\n",
    "        out = tok(ex[\"text\"], truncation=True, padding=True, max_length=max_len, return_attention_mask=True)\n",
    "        out[\"labels\"] = out[\"input_ids\"].copy()\n",
    "        return out\n",
    "\n",
    "    ds = ds.map(_map, batched=True, remove_columns=ds.column_names)\n",
    "    ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "    return ds\n",
    "\n",
    "def _read_json(path: Path):\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d3896a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = _read_json(Path(\"data/train\") / \"test.json\")\n",
    "final_file = _read_json(Path(\"data/final\") / \"test.json\")\n",
    "val_file = _read_json(Path(\"data/val\") / \"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5f2d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [0, 1, 2, 3, 4]\n",
    "file_paths = [f'wiki_json/train/train_shadow_{i}.json' for i in seeds]\n",
    "shadow_datas = {}\n",
    "for i in range(5):\n",
    "    shadow_datas[i] = _read_json(Path(file_paths[i]))\n",
    "for i in range(5):\n",
    "    shadow_datas[i] = [d['text'] for d in shadow_datas[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dfa018cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [[] for _ in range(5)]\n",
    "\n",
    "for i in range(len(train_file)):\n",
    "    for j in range(5):\n",
    "        if j == i % 5:\n",
    "            while train_file[i] in shadow_datas[j]:\n",
    "                shadow_datas[j].remove(train_file[i])\n",
    "            while val_file[i] in shadow_datas[j]:\n",
    "                shadow_datas[j].remove(val_file[i])\n",
    "            while final_file[i] in shadow_datas[j]:\n",
    "                shadow_datas[j].remove(final_file[i])\n",
    "\n",
    "            train_labels[j].append(0)\n",
    "        else:\n",
    "            train_labels[j].append(1)\n",
    "            shadow_datas[j].append(train_file[i])\n",
    "            shadow_datas[j].append(val_file[i])\n",
    "            shadow_datas[j].append(final_file[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34a2f03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 14574 13714\n",
      "1 14778 14704\n",
      "2 14783 14701\n",
      "3 14781 14690\n",
      "4 14777 14694\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i, len(shadow_datas[i]), len(list(set(shadow_datas[i]))))\n",
    "    shadow_datas[i] = [{\"text\": d} for d in shadow_datas[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "77783442",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path('data/shadow')\n",
    "for i in range(5):\n",
    "    dump_json(out_dir / f\"train_shadow_{i}.json\", shadow_datas[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6180a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save(\"data/shadow/labels.npy\", np.array(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1048ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idls24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
